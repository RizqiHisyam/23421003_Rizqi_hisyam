{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmvmv880pKN5"
      },
      "outputs": [],
      "source": [
        "# Upload kaggle.json\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\"'.format(\n",
        "      name=fn))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ubah permission file\n",
        "!chmod 600 /content/kaggle.json"
      ],
      "metadata": {
        "id": "Co8U5Y6QpfYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Setup Kaggle environment\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\""
      ],
      "metadata": {
        "id": "BL5qceV6pgNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download dataset\n",
        "!kaggle datasets download -d alxmamaev/flowers-recognition"
      ],
      "metadata": {
        "id": "Pxl7rW3dpgTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# melakukan ekstraksi pada file zip\n",
        "import zipfile\n",
        "local_zip = 'flowers-recognition.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/flowers-recognition/')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "u33oKc-wpr05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghapus berkas zip yang sudah tidak diperlukan\n",
        "!rm flowers-recognition.zip"
      ],
      "metadata": {
        "id": "cDdcS70HpwPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mendefinisikan direktori utama dataset\n",
        "base_dir = '/content/flowers-recognition/flowers'"
      ],
      "metadata": {
        "id": "5ikJfmlRpy12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(os.listdir(base_dir))"
      ],
      "metadata": {
        "id": "KxHlWUqcp4i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung jumlah gambar pada dataset\n",
        "number_label = {}\n",
        "total_files = 0\n",
        "for i in os.listdir(base_dir):\n",
        "    counting = len(os.listdir(os.path.join(base_dir, i)))\n",
        "    number_label[i] = counting\n",
        "    total_files += counting\n",
        "\n",
        "print(\"Total Files : \" + str(total_files))"
      ],
      "metadata": {
        "id": "iZ7TS354p7hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Visualisasi jumlah gambar tiap kelas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(number_label.keys(), number_label.values());\n",
        "plt.title(\"Jumlah Gambar Tiap Label\");\n",
        "plt.xlabel('Label');\n",
        "plt.ylabel('Jumlah Gambar');"
      ],
      "metadata": {
        "id": "kWZmlKi3p-V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Menampilkan sampel gambar tiap kelas\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "img_each_class = 1\n",
        "img_samples = {}\n",
        "classes = list(number_label.keys())\n",
        "\n",
        "\n",
        "for c in classes:\n",
        "    temp = os.listdir(os.path.join(base_dir, c))[:img_each_class]\n",
        "    for item in temp:\n",
        "        img_path = os.path.join(base_dir, c, item)\n",
        "        img_samples[c] = img_path\n",
        "\n",
        "for i in img_samples:\n",
        "    fig = plt.gcf()\n",
        "    img = mpimg.imread(img_samples[i])\n",
        "    plt.title(i)\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SOsiryRWqDrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (200,200)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 999"
      ],
      "metadata": {
        "id": "LAgBiUrRtvm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan ImageDataGenerator untuk preprocessing\n",
        "import tensorflow as tf\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "UAQxxsrAtxEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyiapkan data train dan data validation\n",
        "train_data = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "valid_data = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=SEED\n",
        ")\n"
      ],
      "metadata": {
        "id": "uHj7Lq7Et0vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Image Augmentation\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(IMAGE_SIZE[0],\n",
        "                                  IMAGE_SIZE[1],\n",
        "                                  3)),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.Rescaling(1./255)\n",
        "  ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "1IXvtcbIt3Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat arsitektur model CNN\n",
        "cnn_model = tf.keras.models.Sequential([\n",
        "  data_augmentation,\n",
        "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Dropout(0.3),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compiling model\n",
        "cnn_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "MMDGeidEt7FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training model CNN\n",
        "cnn_hist = cnn_model.fit(\n",
        "    train_data,\n",
        "    epochs=1,\n",
        "    validation_data = valid_data\n",
        ")"
      ],
      "metadata": {
        "id": "oudicikdt9rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat plot akurasi model CNN\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(cnn_hist.history['accuracy'])\n",
        "plt.plot(cnn_hist.history['val_accuracy'])\n",
        "plt.title('CNN model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Membuat plot loss model CNN\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(cnn_hist.history['loss'])\n",
        "plt.plot(cnn_hist.history['val_loss'])\n",
        "plt.title('CNN model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oH6KxfWht_wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "## Loading VGG16 model\n",
        "base_vgg_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "base_vgg_model.trainable = False\n",
        "\n",
        "# Preprocessing Input\n",
        "vgg_preprocess = tf.keras.applications.vgg16.preprocess_input\n",
        "train_data.preprocessing_function = vgg_preprocess"
      ],
      "metadata": {
        "id": "GcYZXuUhuDg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer learning dengan VGG16\n",
        "vgg_model = tf.keras.models.Sequential([\n",
        "  data_augmentation,\n",
        "  base_vgg_model,\n",
        "  tf.keras.layers.Dropout(0.7),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compiling model\n",
        "vgg_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "jazN_5zCuHEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model VGG16\n",
        "vgg_hist = vgg_model.fit(\n",
        "    train_data,\n",
        "    epochs=1,\n",
        "    validation_data = valid_data\n",
        ")"
      ],
      "metadata": {
        "id": "3JyMWqI9uJ78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Membuat plot akurasi model VGG16\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(vgg_hist.history['accuracy'])\n",
        "plt.plot(vgg_hist.history['val_accuracy'])\n",
        "plt.title('VGG16 model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Membuat plot loss model VGG16\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(vgg_hist.history['loss'])\n",
        "plt.plot(vgg_hist.history['val_loss'])\n",
        "plt.title('VGG16 model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SY9-7N3JuQ5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Loading ResNet50 model\n",
        "base_resnet_model = ResNet50(include_top=False,\n",
        "                   input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3),\n",
        "                   pooling='max',classes=5,\n",
        "                   weights='imagenet')\n",
        "\n",
        "base_resnet_model.trainable = False\n",
        "\n",
        "train_data.preprocessing_function = tf.keras.applications.resnet50.preprocess_input\n",
        "\n",
        "\n",
        "# Transfer learning ResNet50\n",
        "resnet_model = tf.keras.models.Sequential([\n",
        "    data_augmentation,\n",
        "    base_resnet_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(5, activation=\"softmax\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "-6Hl6CBLuT4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "resnet_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "t54EbYVPuWzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model ResNet50\n",
        "resnet_hist = resnet_model.fit(\n",
        "    train_data,\n",
        "    epochs=1,\n",
        "    validation_data = valid_data\n",
        ")"
      ],
      "metadata": {
        "id": "pjNgZJHEuYlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat plot akurasi model ResNet50\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(resnet_hist.history['accuracy'])\n",
        "plt.plot(resnet_hist.history['val_accuracy'])\n",
        "plt.title('ResNet50 model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Membuat plot loss model ResNet50\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(resnet_hist.history['loss'])\n",
        "plt.plot(resnet_hist.history['val_loss'])\n",
        "plt.title('ResNet50 model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cv7R6npKubXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading DenseNet201 model\n",
        "base_densenet_model = tf.keras.applications.DenseNet201(include_top=False,\n",
        "                                                        weights='imagenet',\n",
        "                                                        input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n",
        "                                                        pooling='max')\n",
        "base_densenet_model.trainable=False\n",
        "train_data.preprocessing_function = tf.keras.applications.densenet.preprocess_input"
      ],
      "metadata": {
        "id": "-8c49hLWuyNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer learning DenseNet201\n",
        "densenet_model = tf.keras.models.Sequential([\n",
        "  data_augmentation,\n",
        "  base_densenet_model,\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compiling model\n",
        "densenet_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "_3uMOi20u1GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Melatih model DenseNet201\n",
        "densenet_hist = densenet_model.fit(\n",
        "    train_data,\n",
        "    epochs=1,\n",
        "    validation_data = valid_data\n",
        ")"
      ],
      "metadata": {
        "id": "AStXGArYu4Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat plot akurasi model DenseNet201\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(densenet_hist.history['accuracy'])\n",
        "plt.plot(densenet_hist.history['val_accuracy'])\n",
        "plt.title('DenseNet201 model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Membuat plot loss model DenseNet201\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(densenet_hist.history['loss'])\n",
        "plt.plot(densenet_hist.history['val_loss'])\n",
        "plt.title('DenseNet201 model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3IqU6isfu6Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Membuat plot akurasi empat model sebelumnya untuk dibandingkan\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(cnn_hist.history['val_accuracy'])\n",
        "plt.plot(vgg_hist.history['val_accuracy'])\n",
        "plt.plot(resnet_hist.history['val_accuracy'])\n",
        "plt.plot(densenet_hist.history['val_accuracy'])\n",
        "plt.title('model validation accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['CNN', 'VGG16', 'ResNet50', 'DenseNet201'], loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NIZJs0upvCVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan daftar kelas atau label gambar\n",
        "train_data.class_indices"
      ],
      "metadata": {
        "id": "e3vWz_dKvE5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menguji coba model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "%matplotlib inline\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=IMAGE_SIZE)\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = densenet_model.predict(images, batch_size=BATCH_SIZE)\n",
        "  classes = np.argmax(classes)\n",
        "\n",
        "  print(fn)\n",
        "  if classes==0:\n",
        "    print('daisy')\n",
        "  elif classes==1:\n",
        "    print('dandelion')\n",
        "  elif classes==2:\n",
        "    print('rose')\n",
        "  elif classes==3:\n",
        "    print('sunflower')\n",
        "  else:\n",
        "    print('tulip')"
      ],
      "metadata": {
        "id": "yCNTLJivvHX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "densenet_model.save('model-flowers-recognition.h5')"
      ],
      "metadata": {
        "id": "RsIUF5CyvLBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(densenet_model)\n",
        "tflite_model = converter.convert()\n",
        "with tf.io.gfile.GFile('model-flowers-recognition.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "wbWdzmS0vOa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instal TensorflowJS\n",
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "id": "YlLbSC40vt__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter \\\n",
        "    --input_format=keras \\\n",
        "    /content/model-flowers-recognition.h5 /content/modeltfjs"
      ],
      "metadata": {
        "id": "ZVHNT-A8vw45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}